{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcefefc4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_noise(keypoints_seq, noise_level=0.01):\n",
    "    noise = np.random.normal(0, noise_level, keypoints_seq.shape)\n",
    "    return keypoints_seq + noise\n",
    "def scale_keypoints(keypoints_seq, scale_range=(0.9, 1.1)):\n",
    "    scale = np.random.uniform(*scale_range)\n",
    "    return keypoints_seq * scale\n",
    "def translate_keypoints(keypoints_seq, translate_range=(-0.05, 0.05)):\n",
    "    translation = np.random.uniform(*translate_range, size=(1, keypoints_seq.shape[1]))\n",
    "    return keypoints_seq + translation\n",
    "def rotate_keypoints(sequence, angle_range=(-15, 15)):\n",
    "    angle = np.radians(np.random.uniform(*angle_range))\n",
    "    cos, sin = np.cos(angle), np.sin(angle)\n",
    "    rotation_matrix = np.array([[cos, -sin], [sin, cos]])\n",
    "\n",
    "    sequence = sequence.copy()\n",
    "    for i in range(sequence.shape[0]):\n",
    "        for j in range(0, sequence.shape[1] - 1, 3):  # x, y, z\n",
    "            xy = sequence[i, j:j+2]\n",
    "            rotated_xy = np.dot(rotation_matrix, xy)\n",
    "            sequence[i, j:j+2] = rotated_xy\n",
    "    return sequence\n",
    "def augment_keypoints(keypoints_seq):\n",
    "    # Apply multiple augmentations sequentially\n",
    "    augmented = add_noise(keypoints_seq, noise_level=0.02)\n",
    "    augmented = scale_keypoints(augmented)\n",
    "    augmented = translate_keypoints(augmented)\n",
    "    augmented = rotate_keypoints(augmented)\n",
    "    return augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c4a12d-a867-4409-b53e-92c1fa339c94",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "AUGMENTATIONS_PER_VIDEO = 5 # How many augmented samples per original\n",
    "OUTPUT_DIR = 'data/numpy'\n",
    "DUPLI_DIR='data/Static'\n",
    "for gesture_folder in os.listdir(DUPLI_DIR):\n",
    "    gesture_path = os.path.join(OUTPUT_DIR, gesture_folder)\n",
    "    if not os.path.isdir(gesture_path):\n",
    "        continue\n",
    "    \n",
    "    npy_files = glob(os.path.join(gesture_path, '*.npy'))\n",
    "    for npy_file in npy_files:\n",
    "        if '_aug' in npy_file:\n",
    "            continue  # Skip already augmented files\n",
    "\n",
    "        original_seq = np.load(npy_file)\n",
    "        \n",
    "        for i in range(AUGMENTATIONS_PER_VIDEO):\n",
    "            augmented_seq = augment_keypoints(original_seq)\n",
    "            # augmented_seq = np.clip(augmented_seq, 0, 1)  # If your keypoints are normalized\n",
    "            base_name = os.path.splitext(os.path.basename(npy_file))[0]\n",
    "            save_aug_path = os.path.join(gesture_path, f\"{base_name}_aug{i+1}.npy\")\n",
    "            np.save(save_aug_path, augmented_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a49fa70",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "A\n",
      "Alright\n",
      "Animal\n",
      "B\n",
      "Beautiful\n",
      "Bed\n",
      "Bedroom\n",
      "Bird\n",
      "Black\n",
      "Blind\n",
      "C\n",
      "Cat\n",
      "Chair\n",
      "Colour\n",
      "Cow\n",
      "D\n",
      "Daughter\n",
      "Deaf\n",
      "Dog\n",
      "Door\n",
      "Dream\n",
      "E\n",
      "F\n",
      "Father\n",
      "Fish\n",
      "Friday\n",
      "G\n",
      "Good Morning\n",
      "Good night\n",
      "Grey\n",
      "H\n",
      "Happy\n",
      "He\n",
      "Hello\n",
      "Horse\n",
      "How are you\n",
      "I\n",
      "Ii\n",
      "It\n",
      "J\n",
      "K\n",
      "L\n",
      "Loud\n",
      "M\n",
      "Monday\n",
      "Mother\n",
      "Mouse\n",
      "N\n",
      "O\n",
      "Orange\n",
      "P\n",
      "Parent\n",
      "Pink\n",
      "Pleased\n",
      "Q\n",
      "Quiet\n",
      "R\n",
      "S\n",
      "Sad\n",
      "Saturday\n",
      "She\n",
      "Son\n",
      "Sunday\n",
      "T\n",
      "Table\n",
      "Thank you\n",
      "Thursday\n",
      "Today\n",
      "Tuesday\n",
      "U\n",
      "Ugly\n",
      "V\n",
      "W\n",
      "Wednesday\n",
      "White\n",
      "Window\n",
      "X\n",
      "Y\n",
      "You\n",
      "Z\n",
      "Dataset size: (44268, 25, 127), Labels: (44268,)\n",
      "Classes: {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, 'A': 10, 'Alright': 11, 'Animal': 12, 'B': 13, 'Beautiful': 14, 'Bed': 15, 'Bedroom': 16, 'Bird': 17, 'Black': 18, 'Blind': 19, 'C': 20, 'Cat': 21, 'Chair': 22, 'Colour': 23, 'Cow': 24, 'D': 25, 'Daughter': 26, 'Deaf': 27, 'Dog': 28, 'Door': 29, 'Dream': 30, 'E': 31, 'F': 32, 'Father': 33, 'Fish': 34, 'Friday': 35, 'G': 36, 'Good Morning': 37, 'Good night': 38, 'Grey': 39, 'H': 40, 'Happy': 41, 'He': 42, 'Hello': 43, 'Horse': 44, 'How are you': 45, 'I': 46, 'Ii': 47, 'It': 48, 'J': 49, 'K': 50, 'L': 51, 'Loud': 52, 'M': 53, 'Monday': 54, 'Mother': 55, 'Mouse': 56, 'N': 57, 'O': 58, 'Orange': 59, 'P': 60, 'Parent': 61, 'Pink': 62, 'Pleased': 63, 'Q': 64, 'Quiet': 65, 'R': 66, 'S': 67, 'Sad': 68, 'Saturday': 69, 'She': 70, 'Son': 71, 'Sunday': 72, 'T': 73, 'Table': 74, 'Thank you': 75, 'Thursday': 76, 'Today': 77, 'Tuesday': 78, 'U': 79, 'Ugly': 80, 'V': 81, 'W': 82, 'Wednesday': 83, 'White': 84, 'Window': 85, 'X': 86, 'Y': 87, 'You': 88, 'Z': 89}\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "KEYPOINTS_DIR = 'data/numpy'\n",
    "GESTURES = sorted(os.listdir(KEYPOINTS_DIR))  # e.g., ['hello', 'thank_you']\n",
    "label_map = {gesture: idx for idx, gesture in enumerate(GESTURES)}\n",
    "\n",
    "X, y = [], []\n",
    "\n",
    "for gesture in GESTURES:\n",
    "    print(gesture)\n",
    "    gesture_path = os.path.join(KEYPOINTS_DIR, gesture)\n",
    "    npy_files = glob(os.path.join(gesture_path, '*.npy'))\n",
    "    \n",
    "    for npy_file in npy_files:\n",
    "        keypoints = np.load(npy_file)\n",
    "        if keypoints.shape == (25, 126):\n",
    "            # Add normalized time index to each frame\n",
    "            time_indices = np.linspace(0, 1, 25).reshape(25, 1)\n",
    "            keypoints_with_time = np.concatenate([keypoints, time_indices], axis=1)  # (30, 127)\n",
    "            X.append(keypoints_with_time)\n",
    "            y.append(label_map[gesture])\n",
    "\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(f'Dataset size: {X.shape}, Labels: {y.shape}')\n",
    "print(f'Classes: {label_map}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0369af57",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f60cca2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout, Masking\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3840f298",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y_train))\n",
    "y_train_cat = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0b9d2bc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({46: 773, 58: 432, 47: 432, 49: 432, 6: 408, 25: 408, 20: 408, 2: 408, 81: 408, 3: 408, 10: 408, 89: 408, 66: 408, 5: 408, 40: 408, 87: 408, 79: 408, 51: 408, 9: 408, 32: 408, 73: 408, 67: 408, 13: 408, 1: 408, 7: 408, 82: 408, 57: 408, 31: 408, 36: 408, 53: 408, 0: 408, 60: 408, 86: 408, 64: 408, 4: 408, 50: 408, 8: 408, 63: 389, 37: 389, 48: 389, 45: 389, 75: 389, 88: 389, 41: 389, 11: 389, 43: 389, 19: 389, 68: 389, 70: 389, 52: 389, 14: 389, 38: 389, 65: 389, 27: 389, 42: 389, 17: 389, 18: 384, 26: 384, 71: 384, 62: 384, 59: 384, 33: 384, 84: 384, 39: 384, 61: 384, 23: 384, 55: 384, 44: 379, 24: 379, 34: 379, 56: 379, 21: 379, 12: 379, 28: 379, 35: 370, 69: 370, 77: 369, 78: 369, 54: 369, 72: 369, 83: 369, 76: 365, 74: 336, 22: 336, 29: 336, 30: 336, 16: 331, 85: 331, 15: 331, 80: 326})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "labels = [np.argmax(y) for y in y_train_cat]\n",
    "print(Counter(labels))  # Ensure balanced class counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dabcf027",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking (Masking)           (None, None, 127)         0         \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, None, 256)         262144    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, None, 128)         164352    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirecti  (None, 64)                41216     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               16640     \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 256)               1024      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 90)                11610     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 529882 (2.02 MB)\n",
      "Trainable params: 529370 (2.02 MB)\n",
      "Non-trainable params: 512 (2.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Masking, Bidirectional, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential([\n",
    "    Masking(mask_value=0.0, input_shape=(None, 127)),  # ← None for variable length\n",
    "\n",
    "    Bidirectional(LSTM(128, return_sequences=True)),\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),\n",
    "    Bidirectional(LSTM(32)),\n",
    "\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28d4be94",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "554/554 [==============================] - 517s 684ms/step - loss: 2.6027 - accuracy: 0.3047 - val_loss: 1.5193 - val_accuracy: 0.5539 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "554/554 [==============================] - 173s 313ms/step - loss: 1.1712 - accuracy: 0.6453 - val_loss: 0.8012 - val_accuracy: 0.7530 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "554/554 [==============================] - 76s 138ms/step - loss: 0.7819 - accuracy: 0.7594 - val_loss: 0.6438 - val_accuracy: 0.7957 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "554/554 [==============================] - 76s 138ms/step - loss: 0.6226 - accuracy: 0.8052 - val_loss: 0.4929 - val_accuracy: 0.8362 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "554/554 [==============================] - 76s 137ms/step - loss: 0.5117 - accuracy: 0.8393 - val_loss: 0.4039 - val_accuracy: 0.8688 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "554/554 [==============================] - 77s 138ms/step - loss: 0.4406 - accuracy: 0.8605 - val_loss: 0.3698 - val_accuracy: 0.8815 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "554/554 [==============================] - 77s 139ms/step - loss: 0.3936 - accuracy: 0.8731 - val_loss: 0.4299 - val_accuracy: 0.8641 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "554/554 [==============================] - 77s 139ms/step - loss: 0.3593 - accuracy: 0.8845 - val_loss: 0.2925 - val_accuracy: 0.9064 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "554/554 [==============================] - 77s 140ms/step - loss: 0.3286 - accuracy: 0.8957 - val_loss: 0.2946 - val_accuracy: 0.9043 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "554/554 [==============================] - 78s 140ms/step - loss: 0.2942 - accuracy: 0.9059 - val_loss: 0.2529 - val_accuracy: 0.9172 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "554/554 [==============================] - 77s 139ms/step - loss: 0.2682 - accuracy: 0.9133 - val_loss: 0.2394 - val_accuracy: 0.9233 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "554/554 [==============================] - 78s 140ms/step - loss: 0.2521 - accuracy: 0.9173 - val_loss: 0.2629 - val_accuracy: 0.9174 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "554/554 [==============================] - 78s 141ms/step - loss: 0.2380 - accuracy: 0.9234 - val_loss: 0.1903 - val_accuracy: 0.9375 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "554/554 [==============================] - 79s 142ms/step - loss: 0.2261 - accuracy: 0.9263 - val_loss: 0.2056 - val_accuracy: 0.9339 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "554/554 [==============================] - 78s 141ms/step - loss: 0.2026 - accuracy: 0.9343 - val_loss: 0.2848 - val_accuracy: 0.9073 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "554/554 [==============================] - 78s 140ms/step - loss: 0.1966 - accuracy: 0.9352 - val_loss: 0.1645 - val_accuracy: 0.9447 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "554/554 [==============================] - 78s 141ms/step - loss: 0.2000 - accuracy: 0.9362 - val_loss: 0.1356 - val_accuracy: 0.9552 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "554/554 [==============================] - 78s 141ms/step - loss: 0.1785 - accuracy: 0.9423 - val_loss: 0.1998 - val_accuracy: 0.9354 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "554/554 [==============================] - 78s 141ms/step - loss: 0.1602 - accuracy: 0.9473 - val_loss: 0.1461 - val_accuracy: 0.9522 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "554/554 [==============================] - 79s 143ms/step - loss: 0.1593 - accuracy: 0.9479 - val_loss: 0.1993 - val_accuracy: 0.9369 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "554/554 [==============================] - 78s 142ms/step - loss: 0.1577 - accuracy: 0.9487 - val_loss: 0.1697 - val_accuracy: 0.9473 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "554/554 [==============================] - ETA: 0s - loss: 0.1497 - accuracy: 0.9508  \n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "554/554 [==============================] - 79s 142ms/step - loss: 0.1497 - accuracy: 0.9508 - val_loss: 0.1809 - val_accuracy: 0.9415 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "554/554 [==============================] - 78s 141ms/step - loss: 0.0639 - accuracy: 0.9779 - val_loss: 0.0670 - val_accuracy: 0.9774 - lr: 2.0000e-04\n",
      "Epoch 24/100\n",
      "554/554 [==============================] - 79s 143ms/step - loss: 0.0471 - accuracy: 0.9842 - val_loss: 0.0568 - val_accuracy: 0.9820 - lr: 2.0000e-04\n",
      "Epoch 25/100\n",
      "554/554 [==============================] - 78s 141ms/step - loss: 0.0436 - accuracy: 0.9851 - val_loss: 0.0551 - val_accuracy: 0.9810 - lr: 2.0000e-04\n",
      "Epoch 26/100\n",
      "554/554 [==============================] - 80s 144ms/step - loss: 0.0384 - accuracy: 0.9865 - val_loss: 0.0595 - val_accuracy: 0.9810 - lr: 2.0000e-04\n",
      "Epoch 27/100\n",
      "554/554 [==============================] - 79s 142ms/step - loss: 0.0380 - accuracy: 0.9870 - val_loss: 0.0665 - val_accuracy: 0.9785 - lr: 2.0000e-04\n",
      "Epoch 28/100\n",
      "554/554 [==============================] - 79s 142ms/step - loss: 0.0368 - accuracy: 0.9875 - val_loss: 0.0793 - val_accuracy: 0.9752 - lr: 2.0000e-04\n",
      "Epoch 29/100\n",
      "554/554 [==============================] - 80s 144ms/step - loss: 0.0342 - accuracy: 0.9886 - val_loss: 0.0714 - val_accuracy: 0.9773 - lr: 2.0000e-04\n",
      "Epoch 30/100\n",
      "554/554 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9883  \n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "554/554 [==============================] - 79s 142ms/step - loss: 0.0324 - accuracy: 0.9883 - val_loss: 0.0671 - val_accuracy: 0.9781 - lr: 2.0000e-04\n",
      "Epoch 31/100\n",
      "554/554 [==============================] - 79s 142ms/step - loss: 0.0220 - accuracy: 0.9928 - val_loss: 0.0477 - val_accuracy: 0.9848 - lr: 4.0000e-05\n",
      "Epoch 32/100\n",
      "554/554 [==============================] - 78s 141ms/step - loss: 0.0190 - accuracy: 0.9936 - val_loss: 0.0475 - val_accuracy: 0.9851 - lr: 4.0000e-05\n",
      "Epoch 33/100\n",
      "554/554 [==============================] - 79s 143ms/step - loss: 0.0174 - accuracy: 0.9942 - val_loss: 0.0483 - val_accuracy: 0.9844 - lr: 4.0000e-05\n",
      "Epoch 34/100\n",
      "554/554 [==============================] - 80s 144ms/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 0.0463 - val_accuracy: 0.9837 - lr: 4.0000e-05\n",
      "Epoch 35/100\n",
      "554/554 [==============================] - 79s 142ms/step - loss: 0.0170 - accuracy: 0.9939 - val_loss: 0.0472 - val_accuracy: 0.9850 - lr: 4.0000e-05\n",
      "Epoch 36/100\n",
      "554/554 [==============================] - 78s 142ms/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.0474 - val_accuracy: 0.9843 - lr: 4.0000e-05\n",
      "Epoch 37/100\n",
      "554/554 [==============================] - 78s 142ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 0.0490 - val_accuracy: 0.9842 - lr: 4.0000e-05\n",
      "Epoch 38/100\n",
      "554/554 [==============================] - 78s 141ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.0480 - val_accuracy: 0.9862 - lr: 4.0000e-05\n",
      "Epoch 39/100\n",
      "554/554 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9949  \n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "554/554 [==============================] - 78s 141ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.0483 - val_accuracy: 0.9854 - lr: 4.0000e-05\n",
      "Epoch 40/100\n",
      "554/554 [==============================] - 79s 142ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 0.0464 - val_accuracy: 0.9861 - lr: 8.0000e-06\n",
      "Epoch 41/100\n",
      "554/554 [==============================] - 78s 141ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.0459 - val_accuracy: 0.9869 - lr: 8.0000e-06\n",
      "Epoch 42/100\n",
      "554/554 [==============================] - 78s 141ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.0453 - val_accuracy: 0.9862 - lr: 8.0000e-06\n",
      "Epoch 43/100\n",
      "554/554 [==============================] - 78s 141ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0451 - val_accuracy: 0.9861 - lr: 8.0000e-06\n",
      "Epoch 44/100\n",
      "554/554 [==============================] - 78s 141ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.0462 - val_accuracy: 0.9861 - lr: 8.0000e-06\n",
      "Epoch 45/100\n",
      "554/554 [==============================] - 78s 141ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.0460 - val_accuracy: 0.9862 - lr: 8.0000e-06\n",
      "Epoch 46/100\n",
      "554/554 [==============================] - 79s 142ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.0458 - val_accuracy: 0.9862 - lr: 8.0000e-06\n",
      "Epoch 47/100\n",
      "554/554 [==============================] - 78s 141ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.0463 - val_accuracy: 0.9864 - lr: 8.0000e-06\n",
      "Epoch 48/100\n",
      "554/554 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9957  \n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "554/554 [==============================] - 79s 142ms/step - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.0462 - val_accuracy: 0.9860 - lr: 8.0000e-06\n",
      "Epoch 49/100\n",
      "554/554 [==============================] - 79s 142ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.0463 - val_accuracy: 0.9857 - lr: 1.6000e-06\n",
      "Epoch 50/100\n",
      "554/554 [==============================] - 78s 142ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.0460 - val_accuracy: 0.9862 - lr: 1.6000e-06\n",
      "Epoch 51/100\n",
      "554/554 [==============================] - 79s 142ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.0461 - val_accuracy: 0.9860 - lr: 1.6000e-06\n",
      "Epoch 52/100\n",
      "554/554 [==============================] - 78s 142ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.0460 - val_accuracy: 0.9859 - lr: 1.6000e-06\n",
      "Epoch 53/100\n",
      "554/554 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9960  \n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "554/554 [==============================] - 78s 141ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.0461 - val_accuracy: 0.9858 - lr: 1.6000e-06\n",
      "Epoch 54/100\n",
      "554/554 [==============================] - 78s 141ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.0460 - val_accuracy: 0.9858 - lr: 1.0000e-06\n",
      "Epoch 55/100\n",
      "554/554 [==============================] - 78s 141ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.0460 - val_accuracy: 0.9860 - lr: 1.0000e-06\n",
      "Epoch 56/100\n",
      "554/554 [==============================] - 79s 142ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.0462 - val_accuracy: 0.9860 - lr: 1.0000e-06\n",
      "Epoch 57/100\n",
      "554/554 [==============================] - 78s 141ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.0462 - val_accuracy: 0.9862 - lr: 1.0000e-06\n",
      "Epoch 58/100\n",
      "Restoring model weights from the end of the best epoch: 43.0.0115 - accuracy: 0.9966  \n",
      "554/554 [==============================] - 80s 144ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.0460 - val_accuracy: 0.9861 - lr: 1.0000e-06\n",
      "Epoch 58: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,               # Increased from 10 to 15\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,                # More gradual decay\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    min_lr=1e-6                # Optional lower bound\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train_cat,\n",
    "    validation_data=(X_test, y_test_cat),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d247c762",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('fullset.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
